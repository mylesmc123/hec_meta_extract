{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "prj = \"Z:/Amite/Amite_LWI/Models/Amite_HMS/Amite_HMS.hms\"\n",
    "prj_dir, prj_file_tail = os.path.split(prj)\n",
    "prj_name = prj_file_tail.split(\".\")[0]\n",
    "\n",
    "with open(\"Z:/Amite/Amite_LWI/Models/Amite_HMS/Amite_HMS.hms\", \"r\") as f:\n",
    "     lines = f.readlines()\n",
    "lines = [s.strip('\\n') for s in lines]\n",
    "# lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "keyValueList = copy.deepcopy(lines)  \n",
    "\n",
    "nest_start = 0\n",
    "nestList = []\n",
    "for i,v in enumerate(lines):\n",
    "        if v == 'End:':\n",
    "                # If not the beginning of the file, skip a blank line (+1) for the start of the subList.\n",
    "                if len(nestList) > 0:\n",
    "                        nestList.append(lines[nest_start+1:i])\n",
    "                else:\n",
    "                        nestList.append(lines[nest_start:i])\n",
    "                nest_start = i+1\n",
    "# nestList\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Control', 'Project', 'Basin', 'Precipitation']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the unique headers [Project, Control, Basin, etc.] as a list.\n",
    "headers = []\n",
    "for subList in nestList:\n",
    "    headers.append(subList[0].split(\":\")[0])\n",
    "unique_headers = list(set(headers))\n",
    "unique_headers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Control Files', 'Basin', 'Precipitaion', 'Project'])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dictionary based on keys using the unique headers with values of Title, Filename, and Description\n",
    "kv = {}\n",
    "kv['Control Files'] = {}\n",
    "kv['Basin'] = {}\n",
    "kv['Precipitaion'] = {}\n",
    "headers_with_same_parsing = ['Control', 'Basin', 'Precipitation']\n",
    "\n",
    "for subList in nestList:\n",
    "    header = subList[0].split(\":\")[0]\n",
    "    title = subList[0].split(\":\")[1]\n",
    "    find_str = 'Description'\n",
    "    description = [s for s in subList if find_str in s][0].split(\":\")[1:][0].strip()\n",
    "\n",
    "    if header == 'Project':\n",
    "        find_str = 'File Name'\n",
    "        filename = [s for s in subList if find_str in s][0].split(\":\")[1:][0].strip()\n",
    "        kv['Project'] = {\n",
    "            'Title': title,\n",
    "            'Project Output DSS File': filename,\n",
    "            'Description': description\n",
    "        }\n",
    "    \n",
    "    if any(header == i for i in headers_with_same_parsing):\n",
    "        find_str = 'filename'\n",
    "        filename = [s for s in subList if find_str in s.lower()][0].split(\":\")[1:][0].strip()\n",
    "        kv['Project'][title] = {\n",
    "            'File Name': filename,\n",
    "            'Description': description\n",
    "        }\n",
    "\n",
    "kv.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Z:/Amite/Amite_LWI/Models/Amite_HMS\\\\Amite_HMS.access',\n",
       " 'Z:/Amite/Amite_LWI/Models/Amite_HMS\\\\Amite_HMS.dss',\n",
       " 'Z:/Amite/Amite_LWI/Models/Amite_HMS\\\\Amite_HMS.gage',\n",
       " 'Z:/Amite/Amite_LWI/Models/Amite_HMS\\\\Amite_HMS.hms',\n",
       " 'Z:/Amite/Amite_LWI/Models/Amite_HMS\\\\Amite_HMS.log',\n",
       " 'Z:/Amite/Amite_LWI/Models/Amite_HMS\\\\Amite_HMS.out',\n",
       " 'Z:/Amite/Amite_LWI/Models/Amite_HMS\\\\Amite_HMS.pdata',\n",
       " 'Z:/Amite/Amite_LWI/Models/Amite_HMS\\\\Amite_HMS.run']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob, os\n",
    "# prj_name = kv['Project']['Title']\n",
    "# Get project files\n",
    "prj_files_List = []\n",
    "\n",
    "for pFile in glob.glob(rf'{prj_dir}/{prj_name}.*'):\n",
    "        prj_files_List.append(pFile)\n",
    "\n",
    "prj_files_List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'description': 'Input DSS File ',\n",
       "  'location': 'data/Amite_HMS_TimeSeries.dss',\n",
       "  'source_dataset': None,\n",
       "  'title': 'Amite_HMS_TimeSeries'},\n",
       " {'description': 'Input DSS File ',\n",
       "  'location': 'data/rainfall_stageIV.dss',\n",
       "  'source_dataset': None,\n",
       "  'title': 'rainfall_stageIV'},\n",
       " {'description': 'Input DSS File ',\n",
       "  'location': 'data/Specified_Hyetographs.dss',\n",
       "  'source_dataset': None,\n",
       "  'title': 'Specified_Hyetographs'},\n",
       " {'description': 'Input DSS File ',\n",
       "  'location': 'data/USGS_observed.dss',\n",
       "  'source_dataset': None,\n",
       "  'title': 'USGS_observed'}]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add application_date from prj_file modified date\n",
    "modTimeUnix = os.path.getmtime(prj) \n",
    "kv['application_date'] = datetime.fromtimestamp(modTimeUnix).strftime('%Y-%m-%d')\n",
    "\n",
    "# if args.dss, get dss input files\n",
    "input_dss_dir = r\"Z:\\Amite\\Amite_LWI\\Models\\Amite_HMS\\data\"\n",
    "dss_files_list = []\n",
    "for pFile in glob.glob(rf'{input_dss_dir}/*.dss'):\n",
    "        dss_files_list.append(pFile)\n",
    "\n",
    "# dss_files_list\n",
    "dss_common_files_input = []\n",
    "if len(dss_files_list)>0:\n",
    "        for f in dss_files_list:\n",
    "                head, tail = os.path.split(f)\n",
    "                dss_title = tail.split(\".\")[0]\n",
    "                dss_common_files_input.append(\n",
    "                        {\n",
    "                                \"description\": \"Input DSS File \",\n",
    "                                \"location\": f'data/{tail}',\n",
    "                                \"source_dataset\": None,\n",
    "                                \"title\": dss_title\n",
    "                        },\n",
    "                )\n",
    "dss_common_files_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'description': 'The HMS Project File',\n",
       "   'location': 'Amite_HMS.hms',\n",
       "   'source_dataset': None,\n",
       "   'title': 'Project File'},\n",
       "  {'description': 'There may be multiple basins in the HMS model project',\n",
       "   'location': 'Z:/Amite/Amite_LWI/Models/Amite_HMS/*.basin',\n",
       "   'source_dataset': None,\n",
       "   'title': 'Basin Files'},\n",
       "  {'description': 'There may be multiple Meteorological Models',\n",
       "   'location': 'Z:/Amite/Amite_LWI/Models/Amite_HMS/*.met',\n",
       "   'source_dataset': None,\n",
       "   'title': 'Meteorological Model Files'},\n",
       "  {'description': 'There may be multiple control specifications.',\n",
       "   'location': 'Z:/Amite/Amite_LWI/Models/Amite_HMS/*.control',\n",
       "   'source_dataset': None,\n",
       "   'title': 'Control Specification Files'}],\n",
       " {'description': 'Input DSS File ',\n",
       "  'location': 'data/Amite_HMS_TimeSeries.dss',\n",
       "  'source_dataset': None,\n",
       "  'title': 'Amite_HMS_TimeSeries'},\n",
       " {'description': 'Input DSS File ',\n",
       "  'location': 'data/rainfall_stageIV.dss',\n",
       "  'source_dataset': None,\n",
       "  'title': 'rainfall_stageIV'},\n",
       " {'description': 'Input DSS File ',\n",
       "  'location': 'data/Specified_Hyetographs.dss',\n",
       "  'source_dataset': None,\n",
       "  'title': 'Specified_Hyetographs'},\n",
       " {'description': 'Input DSS File ',\n",
       "  'location': 'data/USGS_observed.dss',\n",
       "  'source_dataset': None,\n",
       "  'title': 'USGS_observed'}]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# open the model application Json template, del unnecessary keys, update, add, export \n",
    "\n",
    "with open(r\"C:\\py\\hec_meta_extract\\example\\input\\json\\hms_model_application.json\", 'r') as f:\n",
    "            model_template_json = json.load(f)\n",
    "# model_template_json\n",
    "# keys to drop from json template\n",
    "drop_keys = ['_id', 'linked_resources', 'common_parameters', 'common_software_version', 'authors', \n",
    "'spatial_extent_resolved', 'spatial_valid_extent_resolved', 'temporal_extent', 'temporal_resolution', \n",
    "'spatial_valid_extent', 'common_files_details', 'grid']\n",
    "for key in drop_keys:\n",
    "    del model_template_json[key]\n",
    "\n",
    "\n",
    "\n",
    "# set basic keywords\n",
    "model_template_json['keywords'] = ['hec-hms','hec','hms','hydrology','model','lwi']\n",
    "\n",
    "model_template_json['purpose'] = kv['Project']['Description']\n",
    "model_template_json['description'] = kv['Project']['Description']\n",
    "model_template_json['title'] = f\"{kv['Project']['Title']} HEC-HMS Model\"\n",
    "\n",
    "# common_files_details[]\n",
    "model_template_json['common_files_details'] = []\n",
    "model_template_json['common_files_details'].append(\n",
    "    [{\n",
    "        \"description\": \"The HMS Project File\",\n",
    "        \"location\": prj_file_tail,\n",
    "        \"source_dataset\": None,\n",
    "        \"title\": \"Project File\"\n",
    "    },\n",
    "    {\n",
    "        \"description\": \"There may be multiple basins in the HMS model project\",\n",
    "        \"location\": f\"{prj_dir}/*.basin\",\n",
    "        \"source_dataset\": None,\n",
    "        \"title\": \"Basin Files\"\n",
    "    },\n",
    "    {\n",
    "        \"description\": \"There may be multiple Meteorological Models\",\n",
    "        \"location\": f\"{prj_dir}/*.met\",\n",
    "        \"source_dataset\": None,\n",
    "        \"title\": \"Meteorological Model Files\"\n",
    "    },\n",
    "    {\n",
    "        \"description\": \"There may be multiple control specifications.\",\n",
    "        \"location\": f\"{prj_dir}/*.control\",\n",
    "        \"source_dataset\": None,\n",
    "        \"title\": \"Control Specification Files\"\n",
    "    }]\n",
    ")\n",
    "model_template_json['common_files_details'].extend(dss_common_files_input)\n",
    "model_template_json['common_files_details']\n",
    "# Map kv dictionary to the model application json\n",
    "# application_date, spatial_extent[0], common_files_details[..], purpose, description, title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output model application json\n",
    "output_prj_json = f'{prj_name}_model_application.json'\n",
    "with open(output_prj_json, \"w\") as outfile:\n",
    "    json.dump(model_template_json, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the simulation Json template, del unnecessary keys, update, add, export\n",
    "\n",
    "with open(r\"C:\\py\\hec_meta_extract\\example\\input\\json\\hms_simulation.json\", 'r') as f:\n",
    "            sim_json = json.load(f)\n",
    "# model_template_json\n",
    "# keys to drop from json template\n",
    "drop_keys = ['_id', 'linked_resources', 'common_parameters', 'common_software_version', 'authors', \n",
    "'spatial_extent_resolved', 'spatial_valid_extent_resolved', 'temporal_extent', 'temporal_resolution', \n",
    "'spatial_valid_extent', 'common_files_details', 'grid']\n",
    "for key in drop_keys:\n",
    "    del sim_json[key]\n",
    "\n",
    "\n",
    "\n",
    "# set basic keywords\n",
    "sim_json['keywords'] = ['hec-hms','hec','hms','hydrology','model','lwi']\n",
    "\n",
    "sim_json['purpose'] = kv['Project']['Description']\n",
    "sim_json['description'] = kv['Project']['Description']\n",
    "sim_json['title'] = f\"{kv['Project']['Title']} HEC-HMS Model\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hec_meta",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "76ecb9a863def9b21f44032a5e87e3ce48447e177fd90c9ddac9401b285a34c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
